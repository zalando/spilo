apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: &cluster_name zalandodemo01
  labels:
    application: spilo
    spilo-cluster: *cluster_name
spec:
  replicas: 3
  serviceName: *cluster_name
  template:
    metadata:
      labels:
        application: spilo
        spilo-cluster: *cluster_name
      annotations:
        # kube2iam should be running in a cluster and
        # app-spilo role needs to be created in the AWS account
        # the cluster is running in. It will be used to ship WALs,
        # and requires access to S3 bucket. See https://github.com/jtblin/kube2iam
        # for the sts::AssumeRole snippets to build trust relationship
        # between the kubernetes woker role and the one below.
        # if you don't use AWS, feel free to remove this annotation.
        iam.amazonaws.com/role: app-spilo
        # forces the scheduler not to put pods on the same node.
        scheduler.alpha.kubernetes.io/affinity: >
            {
                "podAntiAffinity": {
                  "requiredDuringSchedulingIgnoredDuringExecution": [
                    {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "spilo-cluster",
                              "operator": "In",
                              "values": ["zalandodemo01"]
                            }
                          ]
                         },
                         "topologyKey": "kubernetes.io/hostname"
                    }
                  ]
                 }
            }
    spec:
      # service account that allows changing endpoints and assigning pod labels
      # in the given namespace: https://kubernetes.io/docs/user-guide/service-accounts/
      # not required unless you've changed the default service account in the namespace
      # used to deploy Spilo
      serviceAccountName: operator
      containers:
      - name: *cluster_name
        image: registry.opensource.zalan.do/acid/spilo-11:1.5-p5  # put the spilo image here
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8008
          protocol: TCP
        - containerPort: 5432
          protocol: TCP
        volumeMounts:
        - mountPath: /home/postgres/pgdata
          name: pgdata
        env:
        - name: DCS_ENABLE_KUBERNETES_API
          value: 'true'
#        - name: ETCD_HOST
#          value: 'test-etcd.default.svc.cluster.local:2379' # where is your etcd?
#        - name: WAL_S3_BUCKET
#          value: example-spilo-dbaas
#        - name: LOG_S3_BUCKET # may be the same as WAL_S3_BUCKET
#          value: example-spilo-dbaas
#        - name: BACKUP_SCHEDULE
#          value: "00 01 * * *"
        - name: KUBERNETES_SCOPE_LABEL
          value: spilo-cluster
        - name: KUBERNETES_ROLE_LABEL
          value: role
        - name: SPILO_CONFIGURATION
          value: | ## https://github.com/zalando/patroni#yaml-configuration
            bootstrap:
              initdb:
                - auth-host: md5
                - auth-local: trust
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: PGPASSWORD_SUPERUSER
          valueFrom:
            secretKeyRef:
              name: *cluster_name
              key: superuser-password
        - name: PGUSER_ADMIN
          value: superadmin
        - name: PGPASSWORD_ADMIN
          valueFrom:
            secretKeyRef:
              name: *cluster_name
              key: admin-password
        - name: PGPASSWORD_STANDBY
          valueFrom:
            secretKeyRef:
              name: *cluster_name
              key: replication-password
        - name: SCOPE
          value: *cluster_name
        - name: PGROOT
          value: /home/postgres/pgdata/pgroot
      terminationGracePeriodSeconds: 0
  volumeClaimTemplates:
  - metadata:
      labels:
        application: spilo
        spilo-cluster: *cluster_name
      annotations:
        volume.beta.kubernetes.io/storage-class: standard
      name: pgdata
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi

---
apiVersion: v1
kind: Endpoints
metadata:
  name: &cluster_name zalandodemo01
  labels:
    application: spilo
    spilo-cluster: *cluster_name
subsets: []

---
apiVersion: v1
kind: Service
metadata:
  name: &cluster_name zalandodemo01
  labels:
    application: spilo
    spilo-cluster: *cluster_name
spec:
  type: ClusterIP
  ports:
  - name: postgresql
    port: 5432
    targetPort: 5432

---
# headless service to avoid deletion of patronidemo-config endpoint
apiVersion: v1
kind: Service
metadata:
  name: zalandodemo01-config
  labels:
    application: spilo
    spilo-cluster: zalandodemo01
spec:
  clusterIP: None

---
apiVersion: v1
kind: Secret
metadata:
  name: &cluster_name zalandodemo01
  labels:
    application: spilo
    spilo-cluster: *cluster_name
type: Opaque
data:
  superuser-password: emFsYW5kbw==
  replication-password: cmVwLXBhc3M=
  admin-password: YWRtaW4=

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: operator

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: operator
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - create
  - get
  - list
  - patch
  - update
  - watch
  # delete is required only for 'patronictl remove'
  - delete
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - patch
  - update
  # the following three privileges are necessary only when using endpoints
  - create
  - list
  - watch
  # delete is required only for for 'patronictl remove'
  - delete
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - patch
  - update
  - watch
# The following privilege is only necessary for creation of headless service
# for patronidemo-config endpoint, in order to prevent cleaning it up by the
# k8s master. You can avoid giving this privilege by explicitly creating the
# service like it is done in this manifest (lines 160..169)
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - create

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: operator
subjects:
- kind: ServiceAccount
  name: operator
